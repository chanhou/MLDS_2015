{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This version\n",
    "\n",
    "Trying to implement a version about CTC with 3 hidden layer and combine with RNN\n",
    "\n",
    "***Summary***\n",
    "1. Try Deep-LSTM by lasagne\n",
    "- Try dropout layer\n",
    "- [CTC Problem] prefix search decoding? -> blank probability threshold set at 99.99% at paper\n",
    "- Try phoneme base instead of char base\n",
    "\n",
    "***Todo***\n",
    "1. ~~data normalize~~\n",
    "2. CTC correct?\n",
    "- Try phoneme but not character based\n",
    "1. ~~Using oop module~~\n",
    "- ~~Using CTC with log domain and recurrent relationship~~\n",
    "- ~~Add hidden layer before RNN~~\n",
    "- ~~Compile and update and learning~~\n",
    "- ~~func check_label_error~~\n",
    "- ~~data processing to char based~~\n",
    "    - ~~preprocess of data~~\n",
    "    - ~~remove_blank(predict)~~\n",
    "    - ~~remap_back( predict )~~\n",
    "    - ~~change to tri MFCC only~~\n",
    "- ~~Try CTC with character based data (data preprocess) (our data)~~\n",
    "- ~~Check CTC cost correctness~~\n",
    "- ~~Check CTC with y need to unmap or not~~\n",
    "- ~~Add Nestrove momentum~~\n",
    "- ~~Add minibatch~~\n",
    "- ~~Add bidirectional LSTM/RNN~~\n",
    "\n",
    "***Further***\n",
    "1. ~~Add Bidirectional LSTM/RNN~~\n",
    "2. ~~Make mini batch~~\n",
    "- Try phoneme based model\n",
    "\n",
    "***Problem need to understand about RNN***\n",
    "1. [Phd thesis Training RNN , Hessian free method](http://www.cs.utoronto.ca/~ilya/pubs/ilya_sutskever_phd_thesis.pdf)\n",
    "- [Does Theano do automatic unfolding for BPTT?](http://stackoverflow.com/questions/24431621/does-theano-do-automatic-unfolding-for-bptt)\n",
    "- [Github, General purpose Hessian-free optimization in Theano](https://github.com/boulanni/theano-hf)\n",
    "- [Theano scan](http://deeplearning.net/software/theano/library/scan.html#theano.scan)\n",
    "- []()\n",
    "\n",
    "***Problem need to understand about CTC***\n",
    "1. [CTC paper](ftp://ftp.idsia.ch/pub/juergen/icml2006.pdf)\n",
    "\n",
    "***Important References***\n",
    "1. [CTC cost use in our version](https://github.com/mohammadpz/CTC-Connectionist-Temporal-Classification/blob/5b4d4be19805d7795a4293b9c270ef7bf5fafbfc/ctc_cost.py)\n",
    "    - [Discussion](https://github.com/mohammadpz/CTC-Connectionist-Temporal-Classification/issues/1)\n",
    "- How to connect multiple recurrent layers,https://github.com/craffel/nntools/issues/9\n",
    "- https://github.com/craffel/nntools/issues/11\n",
    "- refactor recurrent, update examples, add tests, https://github.com/craffel/nntools/pull/27\n",
    "- example of deep lstm and penn tree,https://github.com/skaae/nntools/blob/combine/examples/lstm.py\n",
    "\n",
    "***Github***\n",
    "1. [Hessian theano](https://github.com/boulanni/theano-hf/blob/master/hf_examples.py)\n",
    "- [Vanilla RNN](https://github.com/mohammadpz/Recurrent-Neural-Networks)\n",
    "- [blocks example, reverse words](https://github.com/mila-udem/blocks-examples/tree/master/reverse_words)\n",
    "- [rnn-ctc, basics ctc](https://github.com/rakeshvar/rnn_ctc/blob/master/ctc.py)\n",
    "- [Lasagne nntools](https://github.com/craffel/nntools/tree/recurrent)\n",
    "- [Theanets, RNN tools](https://github.com/lmjohns3/theanets/blob/master/theanets/layers/recurrent.py)\n",
    "- [LSTM benchmarks example](https://github.com/craffel/lstm_benchmarks/blob/master/lasagne/experiment.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../../../nntools\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 980\n",
      "/home/pika/nntools/lasagne/init.py:86: UserWarning: The uniform initializer no longer uses Glorot et al.'s approach to determine the bounds, but defaults to the range (-0.01, 0.01) instead. Please use the new GlorotUniform initializer to get the old behavior. GlorotUniform is now the default for all layers.\n",
      "  warnings.warn(\"The uniform initializer no longer uses Glorot et al.'s \"\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor as T\n",
    "import numpy as np\n",
    "from theano_toolkit import utils as U\n",
    "from theano_toolkit import updates\n",
    "from theano.printing import Print\n",
    "from theano_toolkit.parameters import Parameters\n",
    "\n",
    "import lasagne\n",
    "from lasagne.layers import *\n",
    "# from lasagne.layers import RecurrentLayer, InputLayer, DenseLayer,\\\n",
    "#     NonlinearityLayer, ReshapeLayer, EmbeddingLayer\n",
    "# from lasagne.layers.recurrent import *\n",
    "\n",
    "from time import time\n",
    "\n",
    "import ctc_cost_2\n",
    "\n",
    "import cPickle\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data part\n",
    "\n",
    "## read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### DataProcessing \n",
    "\n",
    "'''\n",
    "[ INPUT  ] : model { wav, NFCC, ... }\n",
    "[ OUTPUT ] : (Training_data, Validation_data, Testing_Data)\n",
    "\n",
    "- Training_data : x, y { .astype(np.float32)\n",
    "- Validation_data : x, y { .astype(np.float32)\n",
    "- Testing_Data : ( x, id )\n",
    "\n",
    "-- x format : \n",
    "---- MFCC : [ 39-vector ] - \n",
    "---- FBank : [ 69-vector ]\n",
    "---- quadmfcc : [ 39*(1+1+1) - vector ] !!! Wron---- FBank : [ 69-vector ]\n",
    "---- quadmfcc : [ 39*(1+1+1) - vector ] !!! Wrong implementation\n",
    "g implementation\n",
    "---- hexamfcc : [ 39*(4+1+4) - vector ]\n",
    "---- hexaFbank : [ 69*(4+1+4) - vector ]\n",
    "\n",
    "-- y format :\n",
    "\n",
    "---- Now we use 39-phonemes for all : [ 0 0 0 ... 1 .... 0 0 0 ]  as a number of 39\n",
    "---- But answer we get from ./label is [ 48-vector]\n",
    "'''\n",
    "\n",
    "\n",
    "'''\n",
    "input:\n",
    "    MFCC: 39,2-1-2\n",
    "output:\n",
    "    state label: 1943\n",
    "'''\n",
    "\n",
    "'''\n",
    "[ Input  ] :\n",
    "    - mfcc (39*(2+1+2))\n",
    "\n",
    "[ Output ] :\n",
    "    - maxi (1943-D)\n",
    "    \n",
    "'''\n",
    "\n",
    "from itertools import repeat\n",
    "import numpy as np\n",
    "import random\n",
    "# from sklearn import preprocessing\n",
    "\n",
    "# Parameter (note: switch /final/MLDS_Final_Data/ .. if u want\n",
    "MAPPING_FILE = '/home/pika/MLDS_2015/final/MLDS_HW1_RELEASE_v1/phones/48_39.map'\n",
    "MFCC_TRAINING_ARK = '/home/pika/MLDS_2015/final/MLDS_Final_Data/mfcc/train_nor.ark'\n",
    "# MFCC_TRAINING_ARK = '/home/pika/MLDS_2015/final/MLDS_Final_Data/wav_mod/train.ark'\n",
    "\n",
    "# MAXI_TRAINING_LABEL = '/home/pika/MLDS_2015/final/MLDS_HW1_RELEASE_v1/state_label/train.lab'\n",
    "NORMAL_TRAINING_LABEL = '/home/pika/MLDS_2015/final/MLDS_HW1_RELEASE_v1/label/train.lab'\n",
    "\n",
    "sentence_data = '/home/pika/MLDS_2015/final/MLDS_Final_Data/sentence/train_mod.set'\n",
    "\n",
    "\n",
    "def clean_up( y ):\n",
    "    \"\"\"\n",
    "    for final output clean up\n",
    "    B(a − ab−) = B(−aa − −abb) = aab\n",
    "    \"\"\"\n",
    "    answer = []\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        if (i==0):\n",
    "            answer.append(y[i])\n",
    "        if y[i-1] != y[i]:\n",
    "            answer.append(y[i])\n",
    "    \n",
    "    return answer\n",
    "\n",
    "\n",
    "\n",
    "# Dataset \n",
    "def DNNDataset( inputMode ) :\n",
    "    trains = {}\n",
    "    valids = {}\n",
    "    test_data = {}\n",
    "    x_train = []\n",
    "    x_valid = []\n",
    "    y_train = []\n",
    "    y_valid = []\n",
    "    total_result = []\n",
    "    \n",
    "    slide_ration = 0.1\n",
    "    \n",
    "    sentense = {}\n",
    "    char_map = {}\n",
    "    char_unmap = {}\n",
    "    char_count = 0\n",
    "    \n",
    "    with open(sentence_data) as f:\n",
    "        for lines in f:\n",
    "            frames = lines.split(',',1)\n",
    "            frames[1] = frames[1].lower()\n",
    "            if len(frames[1])<2: # empty sentences\n",
    "                prob = frames[0]\n",
    "                print prob\n",
    "                continue\n",
    "            for cha in frames[1][:-2]: # skip \"\\n\" ending punctuation\n",
    "                if cha in ',.!?;:-\"':\n",
    "                    continue\n",
    "                if cha not in char_map:\n",
    "                    char_map[cha] = char_count\n",
    "                    char_unmap[char_count] = cha\n",
    "                    char_count += 1\n",
    "                    \n",
    "    char_map[\"-\"] = char_count # for blank, different with space\n",
    "    char_unmap[char_count] = \"-\"\n",
    "#     print char_map\n",
    "    \n",
    "    with open(sentence_data) as f:\n",
    "        for lines in f:\n",
    "            frames = lines.split(',',1)\n",
    "            frames[1] = frames[1].lower()\n",
    "            if len(frames[1])<2: # empty sentences\n",
    "                prob = frames[0]\n",
    "                continue\n",
    "            sentense[ frames[0] ] = []\n",
    "            for cha in frames[1][:-2]:\n",
    "                if cha in ',.!?;:\"':\n",
    "                    continue\n",
    "                if cha in '-':\n",
    "                    cha = \" \"\n",
    "#                 sentense[ frames[0] ].append( char_map['-'] ) # append blank before each label\n",
    "                sentense[ frames[0] ].append( char_map[cha] )\n",
    "#             sentense[ frames[0] ].append( char_map['-'] ) # append blank in the end\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    # X(INPUT) ---------------------------------------\n",
    "    if inputMode == \"mfcc\":\n",
    "        \n",
    "        # speaker_window -(map)-> mfcc[39]\n",
    "        monoTrains = {}\n",
    "        with open(MFCC_TRAINING_ARK) as f:\n",
    "            for lines in f:\n",
    "                frames = lines.split(' ')\n",
    "                frame2float = [ float(x) for x in frames[1:] ]\n",
    "                monoTrains[frames[0]] = frame2float\n",
    "#                 break\n",
    "        # Initialize : L2 L1 S R1 R2\n",
    "        zeroFrame = list(repeat(0, 39))\n",
    "        prevframeL1 = [ float(x) for x in zeroFrame[:] ]\n",
    "#         prevframeL2 = [ float(x) for x in zeroFrame[:] ]\n",
    "        prevframeR1 = [ float(x) for x in zeroFrame[:] ]\n",
    "#         prevframeR2 = [ float(x) for x in zeroFrame[:] ]\n",
    "        blankframe  = [ float(x) for x in zeroFrame[:] ]\n",
    "        frameNameL1 = \"\"\n",
    "#         frameNameL2 = \"\"\n",
    "        frameNameR1 = \"\"\n",
    "#         frameNameR2 = \"\"\n",
    "        \n",
    "        # Speaker { windows { ... } }\n",
    "        # still is faem0_si1392, bug !\n",
    "        \n",
    "        speaker_data = []\n",
    "        for sample in monoTrains:\n",
    "            frames_info = sample.split('_')\n",
    "            if frames_info[0] not in speaker_data:\n",
    "                speaker_data.append(frames_info[0])\n",
    "\n",
    "        speaker_data = np.array(speaker_data)\n",
    "        speaker_data = np.random.permutation(speaker_data)\n",
    "#         print speaker_data\n",
    "        valid = len(speaker_data)*0.9\n",
    "        speaker_train = speaker_data[ 0 : valid ]\n",
    "        speaker_valid = speaker_data[ valid : ]\n",
    "        \n",
    "        for sample in monoTrains:\n",
    "            frames_info = sample.split('_')\n",
    "            speaker = frames_info[0] + \"_\" + frames_info[1]\n",
    "#             frameNameL2 = frames_info[0] + \"_\" + frames_info[1] + \"_\" + str( (int(frames_info[2])-2))\n",
    "            frameNameL1 = frames_info[0] + \"_\" + frames_info[1] + \"_\" + str( (int(frames_info[2])-1))\n",
    "            frameNameR1 = frames_info[0] + \"_\" + frames_info[1] + \"_\" + str( (int(frames_info[2])+1))\n",
    "#             frameNameR2 = frames_info[0] + \"_\" + frames_info[1] + \"_\" + str( (int(frames_info[2])+2))\n",
    "            \n",
    "            if frames_info[0] in speaker_train:\n",
    "                \n",
    "                if trains.get(speaker) is None:\n",
    "                    trains[speaker] = {}\n",
    "                if   frames_info[2] == \"1\":\n",
    "                    trains[speaker][sample] = blankframe + monoTrains[sample] + monoTrains[frameNameR1]\n",
    "                elif monoTrains.get(frameNameR1) is None:\n",
    "                    trains[speaker][sample] = monoTrains[frameNameL1] + monoTrains[sample] + blankframe\n",
    "                else:\n",
    "                    trains[speaker][sample] = monoTrains[frameNameL1] + monoTrains[sample] + monoTrains[frameNameR1]  \n",
    "#                 trains[speaker][sample] = monoTrains[sample]\n",
    "            else:\n",
    "                if valids.get(speaker) is None:\n",
    "                    valids[speaker] = {}\n",
    "                if   frames_info[2] == \"1\":\n",
    "                    valids[speaker][sample] = blankframe + monoTrains[sample] + monoTrains[frameNameR1]\n",
    "\n",
    "                elif monoTrains.get(frameNameR1) is None:\n",
    "                    valids[speaker][sample] = monoTrains[frameNameL1] + monoTrains[sample] + blankframe\n",
    "                else:\n",
    "                    valids[speaker][sample] = monoTrains[frameNameL1] + monoTrains[sample] + monoTrains[frameNameR1]\n",
    "#                 valids[speaker][sample] = monoTrains[sample]\n",
    "\n",
    "        monoTrains.clear()\n",
    "        \n",
    "        phones_mapping = {}\n",
    "        result_mapping = {}\n",
    "        y_trains_phone = {}\n",
    "        with open(MAPPING_FILE) as f:\n",
    "            i = 0\n",
    "            for lines in f :\n",
    "                phones = lines.split('\\t')\n",
    "                phones_mapping[phones[0]] = i\n",
    "                i += 1\n",
    "                \n",
    "        with open(MAPPING_FILE) as f:    \n",
    "            for lines in f :\n",
    "                phones = lines.split('\\t')\n",
    "                result_mapping[ phones_mapping[phones[0]] ] = phones[1]\n",
    "        \n",
    "        record_speaker = []\n",
    "        with open(NORMAL_TRAINING_LABEL) as f:\n",
    "            for lines in f:\n",
    "                # print lines\n",
    "                byenextline = lines.split('\\n')\n",
    "                label_info = byenextline[0].split(',')\n",
    "                frame_info = label_info[0].split('_')\n",
    "                speaker = frame_info[0] + \"_\" + frame_info[1]\n",
    "                if (speaker not in y_trains_phone):\n",
    "                    y_trains_phone[ speaker ] = []\n",
    "                    record_speaker.append(speaker)\n",
    "                y_trains_phone[ speaker ].append( phones_mapping[label_info[1].rstrip('\\n')] ) # a class number is enough\n",
    "                \n",
    "#         print record_speaker\n",
    "        for sss in record_speaker:\n",
    "#             print y_trains_phone[sss]\n",
    "            y_trains_phone[sss] = clean_up(y_trains_phone[sss])\n",
    "#             print y_trains_phone[sss]\n",
    "#             break\n",
    "                        \n",
    "        \n",
    "        for sample in trains:\n",
    "#             print sample\n",
    "#             print len(trains[sample])\n",
    "            \n",
    "            if sample in sentense:\n",
    "                temp = []\n",
    "                for i in range(len(trains[sample])):\n",
    "                    temp.append( floatX( trains[sample][sample + \"_\" + str(i+1)] ))\n",
    "                    \n",
    "\n",
    "                x_train.append( floatX(temp ))\n",
    "                \n",
    "                y_train.append(floatX(y_trains_phone[sample]))\n",
    "\n",
    "#                 y_train.append( floatX(sentense[sample]) )\n",
    "\n",
    "        trains.clear()\n",
    "        \n",
    "        for sample in valids:\n",
    "#             print sample\n",
    "#             print len(trains[sample])\n",
    "            if sample in sentense:\n",
    "                temp = []\n",
    "                for i in range(len(valids[sample])):\n",
    "                    ( temp.append( floatX ( valids[sample][sample + \"_\" + str(i+1)]) ))\n",
    "                x_valid.append( floatX(temp ))\n",
    "                y_valid.append(floatX(y_trains_phone[sample]))\n",
    "                \n",
    "    \n",
    "# #     print \"normalized\"\n",
    "# #     x_train = preprocessing.scale( x_train)\n",
    "# #     x_valid = preprocessing.scale( x_valid)\n",
    "    \n",
    "#     trains.clear()\n",
    "#     valids.clear()\n",
    "        \n",
    "    return char_map, char_unmap, phones_mapping, result_mapping, x_train, y_train, x_valid, y_valid\n",
    "\n",
    "def floatX(X):\n",
    "    return np.asarray(X, dtype=theano.config.floatX)\n",
    "\n",
    "def vectorized_result ( j , siz) :\n",
    "    e = np.zeros((siz, 1))\n",
    "    e[j] = 1.0\n",
    "    return np.reshape( e, siz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcth0_sx219\n"
     ]
    }
   ],
   "source": [
    "char_map, char_unmap, phones_mapping, result_mapping, x_train, y_train, x_valid, y_valid = DNNDataset(\"mfcc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print y_train[0]\n",
    "# x_train[0][0].shape[0]\n",
    "print (char_unmap)\n",
    "print len(char_unmap)\n",
    "\n",
    "print len(x_train)\n",
    "print len(x_train[0])\n",
    "print x_train[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print x_train.shape\n",
    "# print x_train[0].shape\n",
    "# print x_train[0][1]\n",
    "len(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print x_test[0].shape\n",
    "# print x_test[0][1][0]\n",
    "len(phones_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data part\n",
    "\n",
    "## make batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_batches_X(X, length, batch_size=30):\n",
    "    '''\n",
    "    https://github.com/craffel/lstm_benchmarks/blob/master/lasagne/experiment.py\n",
    "    \n",
    "    Convert a list of matrices into batches of uniform length\n",
    "    :parameters:\n",
    "        - X : list of np.ndarray\n",
    "            List of matrices\n",
    "        - length : int\n",
    "            Desired sequence length.  Smaller sequences will be padded with 0s,\n",
    "            longer will be truncated.\n",
    "        - batch_size : int\n",
    "            Mini-batch size\n",
    "    :returns:\n",
    "        - X_batch : np.ndarray\n",
    "            Tensor of time series matrix batches,\n",
    "            shape=(n_batches, length, batch_size, n_features)\n",
    "        - X_mask : np.ndarray\n",
    "            shape=(n_batches, length, batch_size)\n",
    "            Mask denoting whether to include each time step of each time series\n",
    "            matrix\n",
    "    '''\n",
    "    n_batches = len(X)//batch_size\n",
    "    \n",
    "    # Lasagne format\n",
    "    X_batch = np.zeros((n_batches, batch_size, length, X[0].shape[1]),\n",
    "                       dtype=theano.config.floatX)\n",
    "    # Else format\n",
    "#     X_batch = np.zeros((n_batches, length, batch_size, X[0].shape[1]),\n",
    "#                        dtype=theano.config.floatX)\n",
    "    \n",
    "#     X_mask = np.zeros(X_batch.shape, dtype=np.bool)\n",
    "    \n",
    "    X_mask = np.zeros((n_batches, length, batch_size ), dtype=theano.config.floatX)\n",
    "#     X_mask = np.zeros((n_batches,  batch_size, length ), dtype=theano.config.floatX)\n",
    "\n",
    "    \n",
    "    \n",
    "    for b in range(n_batches): \n",
    "        for n in range(batch_size): # go thorough batch size\n",
    "            \n",
    "            X_m = X[b*batch_size + n] # seq_length X feature dim\n",
    "            \n",
    "            X_batch[b, n, :X_m.shape[0]] = X_m[:length]\n",
    "#             X_batch[b, :X_m.shape[0], n] = X_m[:length]\n",
    "            \n",
    "#             X_mask[b, n, :X_m.shape[0]] = 1\n",
    "            X_mask[b, :X_m.shape[0], n] = 1\n",
    "            \n",
    "    return X_batch, X_mask\n",
    "\n",
    "def make_batches_Y( X, length, batch_size=30):\n",
    "    '''\n",
    "    https://github.com/craffel/lstm_benchmarks/blob/master/lasagne/experiment.py\n",
    "    \n",
    "    Convert a list of matrices into batches of uniform length\n",
    "    :parameters:\n",
    "        - X : list of np.ndarray\n",
    "            List of matrices\n",
    "        - length : int\n",
    "            Desired sequence length.  Smaller sequences will be padded with 0s,\n",
    "            longer will be truncated.\n",
    "        - batch_size : int\n",
    "            Mini-batch size\n",
    "    :returns:\n",
    "        - X_batch : np.ndarray\n",
    "            Tensor of time series matrix batches,\n",
    "            shape=(n_batches, length, batch_size )\n",
    "        - X_mask : np.ndarray\n",
    "            Mask denoting whether to include each time step of each time series\n",
    "            matrix\n",
    "    '''\n",
    "    n_batches = len(X)//batch_size\n",
    "    \n",
    "    X_batch = np.zeros( (n_batches, length, batch_size ), dtype='float32')\n",
    "    \n",
    "    X_mask = np.zeros(X_batch.shape, dtype=theano.config.floatX)\n",
    "    \n",
    "    for b in range(n_batches):\n",
    "        for n in range(batch_size):\n",
    "            X_m = X[ b*batch_size + n ]\n",
    "            X_batch[b, :X_m.shape[0], n ] = X_m[:length]\n",
    "            X_mask[b, :X_m.shape[0], n] = 1\n",
    "    return X_batch, X_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "# Find the longest sequence\n",
    "length_x = max(max([X.shape[0] for X in x_train]),\n",
    "             max([X.shape[0] for X in x_valid]))\n",
    "length_y = max(max([X.shape[0] for X in y_train]),\n",
    "             max([X.shape[0] for X in y_valid]))\n",
    "\n",
    "# Convert to batches of time series of uniform length\n",
    "# x_train_mask: seq_length X batch_size\n",
    "x_train, x_train_mask = make_batches_X(x_train, length_x, batch_size)\n",
    "# y_train_mask: output_length X batch_size\n",
    "# y_pred_mask = x_train_mask, since pred by sequence\n",
    "y_train, y_train_mask = make_batches_Y(y_train, length_y, batch_size)\n",
    "x_valid, x_valid_mask = make_batches_X(x_valid, length_x, batch_size)\n",
    "y_valid, y_valid_mask = make_batches_Y(y_valid, length_y, batch_size)\n",
    "\n",
    "# x_train_t, x_train_mask = make_batches_X(x_train, length_x, batch_size)\n",
    "# # y_train_mask: output_length X batch_size\n",
    "# # y_pred_mask = x_train_mask, since pred by sequence\n",
    "# y_train_t, y_train_mask = make_batches_Y(y_train, length_y, batch_size)\n",
    "# x_valid_t, x_valid_mask = make_batches_X(x_valid, length_x, batch_size)\n",
    "# y_valid_t, y_valid_mask = make_batches_Y(y_valid, length_y, batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103, 32, 777, 117)\n",
      "(11, 32, 777, 117)\n",
      "(103, 74, 32)\n",
      "(11, 74, 32)\n",
      "================mask================\n",
      "(103, 777, 32)\n",
      "(11, 74, 32)\n"
     ]
    }
   ],
   "source": [
    "print x_train.shape\n",
    "print x_valid.shape\n",
    "print y_train.shape\n",
    "print y_valid.shape\n",
    "print \"================mask================\"\n",
    "print x_train_mask.shape\n",
    "print y_valid_mask.shape\n",
    "\n",
    "# print x_train_mask[0][400][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train[0][20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([1,0,0,0,1])\n",
    "a[np.nonzero(b)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data part\n",
    "\n",
    "## decode for phone based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "credit by NLTK package of measure edit distance\n",
    "'''\n",
    "\n",
    "def _edit_dist_init(len1, len2):\n",
    "    lev = []\n",
    "    for i in range(len1):\n",
    "        lev.append([0] * len2)  # initialize 2D array to zero\n",
    "    for i in range(len1):\n",
    "        lev[i][0] = i           # column 0: 0,1,2,3,4,...\n",
    "    for j in range(len2):\n",
    "        lev[0][j] = j           # row 0: 0,1,2,3,4,...\n",
    "    return lev\n",
    "\n",
    "\n",
    "def _edit_dist_step(lev, i, j, s1, s2, transpositions=False):\n",
    "    c1 = s1[i - 1]\n",
    "    c2 = s2[j - 1]\n",
    "\n",
    "    # skipping a character in s1\n",
    "    a = lev[i - 1][j] + 1\n",
    "    # skipping a character in s2\n",
    "    b = lev[i][j - 1] + 1\n",
    "    # substitution\n",
    "    c = lev[i - 1][j - 1] + (c1 != c2)\n",
    "\n",
    "    # transposition\n",
    "    d = c + 1  # never picked by default\n",
    "    if transpositions and i > 1 and j > 1:\n",
    "        if s1[i - 2] == c2 and s2[j - 2] == c1:\n",
    "            d = lev[i - 2][j - 2] + 1\n",
    "\n",
    "    # pick the cheapest\n",
    "    lev[i][j] = min(a, b, c, d)\n",
    "\n",
    "\n",
    "def check_label_error( real , predict, transpositions=False):\n",
    "    ## length of real >= length of predict\n",
    "    \"\"\"\n",
    "    Calculate the Levenshtein edit-distance between two strings.\n",
    "    The edit distance is the number of characters that need to be\n",
    "    substituted, inserted, or deleted, to transform s1 into s2.  For\n",
    "    example, transforming \"rain\" to \"shine\" requires three steps,\n",
    "    consisting of two substitutions and one insertion:\n",
    "    \"rain\" -> \"sain\" -> \"shin\" -> \"shine\".  These operations could have\n",
    "    been done in other orders, but at least three steps are needed.\n",
    "\n",
    "    This also optionally allows transposition edits (e.g., \"ab\" -> \"ba\"),\n",
    "    though this is disabled by default.\n",
    "\n",
    "    :param s1, s2: The strings to be analysed\n",
    "    :param transpositions: Whether to allow transposition edits\n",
    "    :type s1: str\n",
    "    :type s2: str\n",
    "    :type transpositions: bool\n",
    "    :rtype int\n",
    "    \"\"\"\n",
    "    # set up a 2-D array\n",
    "    len1 = len(predict)\n",
    "    len2 = len(real)\n",
    "    lev = _edit_dist_init(len1 + 1, len2 + 1)\n",
    "\n",
    "    # iterate over the array\n",
    "    for i in range(len1):\n",
    "        for j in range(len2):\n",
    "            _edit_dist_step(lev, i + 1, j + 1, predict, real, transpositions=transpositions)\n",
    "            \n",
    "    return lev[len1][len2]*1.0/len2\n",
    "\n",
    "\n",
    "def clean_up_phone( y ):\n",
    "    \"\"\"\n",
    "    for final output clean up\n",
    "    B(a − ab−) = B(−aa − −abb) = aab\n",
    "    \"\"\"\n",
    "    answer = []\n",
    "\n",
    "    for i in range(len(y)):\n",
    "        \n",
    "        if y[i] == len(phones_mapping): # blank\n",
    "                continue\n",
    "        if i != 0:\n",
    "            if y[i-1] != y[i]:\n",
    "                answer.append(y[i])\n",
    "        else:\n",
    "            answer.append(y[i])\n",
    "    \n",
    "    return answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def check_phone_err(y_actual, y_pred, y_mask_actual, y_mask_pred, batch_size):\n",
    "    \n",
    "    err = 0.\n",
    "    for i in xrange(batch_size):\n",
    "#         print i\n",
    "        mask_actual = np.swapaxes( y_mask_actual, 0, 1)[i]\n",
    "        ans_actual = np.swapaxes( y_actual, 0 , 1)[i]\n",
    "        mask_pred = np.swapaxes( y_mask_pred, 0, 1)[i]\n",
    "        ans_pred = y_pred[i]\n",
    "        \n",
    "        y_rrr = ans_actual[ np.nonzero(mask_actual) ]\n",
    "        y_ppp = ans_pred[ np.nonzero(mask_pred) ]\n",
    "        \n",
    "        y_ppp = clean_up_phone( y_ppp )\n",
    "        \n",
    "#         print \"Target \",y_rrr\n",
    "#         print \"\\t=>\", y_ppp\n",
    "        \n",
    "        err += check_label_error(y_rrr, y_ppp)\n",
    "        \n",
    "#         score += accuracy_score(y_true, y_pred)\n",
    "    \n",
    "    return err\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = np.array([0,0,1,2,3,3,3,48,2,2,3,3,2,3,3,4])\n",
    "b = np.array([48,48,1,1,2,3,3,48,2,2,3,2,3,3,4,5])\n",
    "\n",
    "# print clean_up_phone(b)\n",
    "check_label_error(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train_mask[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check_phone_err(y_actual, y_pred, y_mask_actual, y_mask_pred, batch_size):\n",
    "print np.argmax(abc[0],axis=2).shape\n",
    "check_phone_err(y_train[0], np.argmax(abc[0],axis=2), y_train_mask[0], x_train_mask[0],  batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "class end_to_end():\n",
    "    \n",
    "    def __init__(self, input_shape, max_seq_length, hidden_layer, rnn_hidden_layer,\n",
    "                 batch, max_epochs, eval_size, output_num_units,\n",
    "                 patience, up_learning_rate, up_momentum, file_name):\n",
    "        \n",
    "        self.input_shape = input_shape # [batch, dim]\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.hidden_layer = hidden_layer # hidden [l1, l2, l3]\n",
    "        self.rnn_hidden_layer = rnn_hidden_layer # rnn hidden [l1]\n",
    "        self.output_num_units = output_num_units # [ # of class ]\n",
    "        \n",
    "        self.batch = batch\n",
    "        self.max_epochs = max_epochs\n",
    "        self.eval_size = eval_size\n",
    "        \n",
    "        self.up_learning_rate = up_learning_rate\n",
    "        self.up_momentum = up_momentum\n",
    "                \n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_params = None\n",
    "        \n",
    "        self.train_history_ = []\n",
    "        \n",
    "        self.file_name = file_name\n",
    "        \n",
    "        self.drop_frac = 0.2\n",
    "#         X = T.matrix('X')\n",
    "#         Y = T.ivector('Y')     \n",
    "        \n",
    "        \"\"\"\n",
    "        input data type\n",
    "        y_hat : T x B x C+1\n",
    "        y : L x B\n",
    "        y_hat_mask : T x B\n",
    "        y_mask : L x B\n",
    "        \"\"\"\n",
    "        \n",
    "        # T x B x F\n",
    "        # B X T X F (Lasagne format)\n",
    "        x = T.tensor3('X', dtype=theano.config.floatX)\n",
    "        # L x B\n",
    "        y = T.matrix('y', dtype=theano.config.floatX)\n",
    "\n",
    "        # L x B\n",
    "        y_mask = T.matrix('y_mask', dtype=theano.config.floatX)\n",
    "        # T x B\n",
    "        y_hat_mask = T.matrix('y_hat_mask', dtype=theano.config.floatX)\n",
    "    \n",
    "        # Min/max sequence length\n",
    "#         MIN_LENGTH = 50\n",
    "        MAX_LENGTH = max_seq_length\n",
    "        # Number of units in the hidden (recurrent) layer\n",
    "        N_HIDDEN = hidden_layer[0]\n",
    "        # Number of training sequences in each batch\n",
    "        N_BATCH = batch\n",
    "        # Optimization learning rate\n",
    "        GRAD_CLIP = 100\n",
    "        # How often should we check the output?\n",
    "        EPOCH_SIZE = 100\n",
    "        # Number of epochs to train the net\n",
    "        NUM_EPOCHS = 10\n",
    "        \n",
    "        #===========================================================================================\n",
    "        # Bi RNN\n",
    "        #===========================================================================================\n",
    "\n",
    "        # Recurrent layers expect input of shape\n",
    "        # (batch size, max sequence length, number of features)\n",
    "        # T x B x F\n",
    "#         l_in = lasagne.layers.InputLayer(shape=( N_BATCH, MAX_LENGTH,  self.input_shape[1]))\n",
    "        \n",
    "        # We're using a bidirectional network, which means we will combine two\n",
    "        # RecurrentLayers, one with the backwards=True keyword argument.\n",
    "        # Setting a value for grad_clipping will clip the gradients in the layer\n",
    "#         l_forward = lasagne.layers.RecurrentLayer(l_in, N_HIDDEN, grad_clipping=GRAD_CLIP,\n",
    "#                                                   W_in_to_hid=lasagne.init.HeUniform(),\n",
    "#                                                   W_hid_to_hid=lasagne.init.HeUniform(),\n",
    "#                                                   nonlinearity=lasagne.nonlinearities.tanh)\n",
    "#         l_backward = lasagne.layers.RecurrentLayer(l_in, N_HIDDEN, grad_clipping=GRAD_CLIP,\n",
    "#                                                    W_in_to_hid=lasagne.init.HeUniform(),\n",
    "#                                                    W_hid_to_hid=lasagne.init.HeUniform(),\n",
    "#                                                    nonlinearity=lasagne.nonlinearities.tanh, \n",
    "#                                                    backwards=True)\n",
    "        # We'll use an elementwise sum to combine the forward/backward layers\n",
    "#         l_sum = lasagne.layers.ElemwiseSumLayer([l_forward, l_backward])\n",
    "        \n",
    "        # We need a reshape layer which combines the first (batch size) and second\n",
    "        # (number of timesteps) dimensions, otherwise the DenseLayer will treat the\n",
    "        # number of time steps as a feature dimension\n",
    "#         l_reshape = lasagne.layers.ReshapeLayer( l_sum, (N_BATCH*MAX_LENGTH, N_HIDDEN))\n",
    "        \n",
    "        #===========================================================================================\n",
    "        # dEEP lSTM\n",
    "        #===========================================================================================\n",
    "        \n",
    "        # Recurrent layers expect input of shape\n",
    "        # (batch size, max sequence length, number of features)\n",
    "        l_in = lasagne.layers.InputLayer(shape=(N_BATCH, MAX_LENGTH,  self.input_shape[1]))\n",
    "        \n",
    "        l_in_gau = lasagne.layers.GaussianNoiseLayer(l_in, sigma=0.5, )\n",
    "        \n",
    "        # LSTM layer 1\n",
    "        l_forward_1 = lasagne.layers.LSTMLayer(l_in_gau, num_units=hidden_layer[0], \n",
    "                                               learn_init=True, peepholes=True)\n",
    "        l_backward_1 = lasagne.layers.LSTMLayer(l_in, num_units=hidden_layer[0],\n",
    "                                                backwards=True, learn_init=True, peepholes=True)\n",
    "        l_recurrent_1 = ElemwiseSumLayer([l_forward_1, l_backward_1])\n",
    "  \n",
    "        # concatenate forward and backward LSTM layers\n",
    "#         l_fwd_reshape_1 = lasagne.layers.ReshapeLayer(l_forward_1, (N_BATCH*MAX_LENGTH, hidden_layer[0]))\n",
    "#         l_bck_reshape_1 = lasagne.layers.ReshapeLayer(l_backward_1, (N_BATCH*MAX_LENGTH, hidden_layer[0]))\n",
    "#         l_recurrent_1 = lasagne.layers.ConcatLayer([l_fwd_reshape_1, l_bck_reshape_1], axis=1)\n",
    "        \n",
    "#         if self.drop_frac > 0:\n",
    "#             l_drp_1 = lasagne.layers.DropoutLayer(l_recurrent_1, p = 0.2 )\n",
    "#         else:\n",
    "#             l_drp_1 = l_recurrent_1\n",
    "\n",
    "        # LSTM layer 2\n",
    "        l_forward_2 = lasagne.layers.LSTMLayer(l_recurrent_1, num_units=hidden_layer[1], \n",
    "                                               learn_init=True, peepholes=True)\n",
    "        l_backward_2 = lasagne.layers.LSTMLayer(l_recurrent_1, num_units=hidden_layer[1],\n",
    "                                                backwards=True, learn_init=True, peepholes=True)\n",
    "        l_recurrent_2 = ElemwiseSumLayer([l_forward_2, l_backward_2])\n",
    "        \n",
    "#         if self.drop_frac > 0:\n",
    "#             l_drp_2 = lasagne.layers.DropoutLayer(l_recurrent_2, p = 0.2 )\n",
    "#         else:\n",
    "#             l_drp_2 = l_recurrent_2\n",
    "        \n",
    "        # LSTM layer 3\n",
    "        l_forward_3 = lasagne.layers.LSTMLayer(l_recurrent_2, num_units=hidden_layer[2], \n",
    "                                               learn_init=True, peepholes=True)\n",
    "        l_backward_3 = lasagne.layers.LSTMLayer(l_recurrent_2, num_units=hidden_layer[2],\n",
    "                                                backwards=True, learn_init=True, peepholes=True)\n",
    "        l_recurrent_3 = ElemwiseSumLayer( [l_forward_3, l_backward_3] )\n",
    "        \n",
    "#         if self.drop_frac > 0:\n",
    "#             l_drp_3 = lasagne.layers.DropoutLayer(l_recurrent_3, p = 0.2 )\n",
    "#         else:\n",
    "#             l_drp_3 = l_recurrent_3\n",
    "\n",
    "        \n",
    "        # LSTM layer 4\n",
    "        l_forward_4 = lasagne.layers.LSTMLayer(l_recurrent_3, num_units=hidden_layer[3], \n",
    "                                               learn_init=True, peepholes=True)\n",
    "        l_backward_4 = lasagne.layers.LSTMLayer(l_recurrent_3, num_units=hidden_layer[3],\n",
    "                                                backwards=True, learn_init=True, peepholes=True)\n",
    "        l_recurrent_4 = ElemwiseSumLayer( [l_forward_4, l_backward_4] )\n",
    "\n",
    "#         if self.drop_frac > 0:\n",
    "#             l_drp_4 = lasagne.layers.DropoutLayer(l_recurrent_4, p = 0.2 )\n",
    "#         else:\n",
    "#             l_drp_4 = l_recurrent_4\n",
    "            \n",
    "        # LSTM layer 5\n",
    "#         l_forward_5 = lasagne.layers.LSTMLayer(l_drp_4, num_units=hidden_layer[4], \n",
    "#                                                learn_init=True, peepholes=True)\n",
    "#         l_backward_5 = lasagne.layers.LSTMLayer(l_drp_4, num_units=hidden_layer[4],\n",
    "#                                                 backwards=True, learn_init=True, peepholes=True)\n",
    "#         l_recurrent_5 = ElemwiseSumLayer( [l_forward_5, l_backward_5] )\n",
    "\n",
    "#         if self.drop_frac > 0:\n",
    "#             l_drp_5 = lasagne.layers.DropoutLayer(l_recurrent_5, p = 0.2 )\n",
    "#         else:\n",
    "#             l_drp_5 = l_recurrent_5\n",
    "\n",
    "\n",
    "        \n",
    "        l_reshape = lasagne.layers.ReshapeLayer(l_recurrent_4,\n",
    "                                               (N_BATCH*MAX_LENGTH, hidden_layer[3]))\n",
    "\n",
    "        \n",
    "        #===========================================================================================\n",
    "        # COMMON SETUP\n",
    "        #===========================================================================================\n",
    "        \n",
    "        # Our output layer is a simple dense connection\n",
    "        l_recurrent_out = lasagne.layers.DenseLayer( l_reshape, num_units= output_num_units[0] ,\n",
    "                                                    nonlinearity=lasagne.nonlinearities.identity)\n",
    "        \n",
    "        # Now, reshape the output back to the RNN format\n",
    "        l_out_shp = lasagne.layers.ReshapeLayer(l_recurrent_out, (N_BATCH, MAX_LENGTH, output_num_units[0] ))\n",
    "        \n",
    "        # dimshuffle to shape format (input_seq_len, batch_size, num_classes + 1)\n",
    "        l_out_shp_ctc = lasagne.layers.DimshuffleLayer(l_out_shp, (1, 0, 2))\n",
    "\n",
    "        l_out_softmax = lasagne.layers.NonlinearityLayer(\n",
    "                            l_recurrent_out, nonlinearity=lasagne.nonlinearities.softmax)\n",
    "        l_out_softmax_shp = lasagne.layers.ReshapeLayer(\n",
    "                            l_out_softmax, (N_BATCH, MAX_LENGTH, output_num_units[0] ))\n",
    "        \n",
    "        # since we use gaussian noise in input, False means use noise, True means dont use noise\n",
    "        output_lin_ctc_train = lasagne.layers.get_output(l_out_shp_ctc, x, deterministic=False)\n",
    "        output_softmax_train = lasagne.layers.get_output(l_out_softmax_shp, x, deterministic=False)\n",
    "        \n",
    "        output_lin_ctc_val = lasagne.layers.get_output(l_out_shp_ctc, x, deterministic=True)\n",
    "        output_softmax_val = lasagne.layers.get_output(l_out_softmax_shp, x, deterministic=True)\n",
    "        \n",
    "        self.all_params = lasagne.layers.get_all_params(l_out_shp)\n",
    "\n",
    "        # the CTC cross entropy between y and linear output network\n",
    "        pseudo_cost = ctc_cost_2.pseudo_cost(\n",
    "            y, output_lin_ctc_train, y_mask, y_hat_mask,\n",
    "            skip_softmax=True)\n",
    "        \n",
    "        \n",
    "        pseudo_cost_grad = T.grad(pseudo_cost.mean(), self.all_params)\n",
    "        true_cost = ctc_cost_2.cost(y, output_softmax_train.dimshuffle(1, 0, 2), y_mask, y_hat_mask)\n",
    "        cost = T.mean(true_cost)\n",
    "        updates = lasagne.updates.rmsprop(pseudo_cost_grad, self.all_params, learning_rate=0.0001)\n",
    "\n",
    "        self.train = theano.function(\n",
    "            inputs = [x, y, y_hat_mask, y_mask],\n",
    "            outputs = [ pseudo_cost.mean(), cost, output_softmax_train ],\n",
    "#             outputs = [output_lin_ctc, output_softmax, cost],\n",
    "            updates=updates\n",
    "        )\n",
    "        \n",
    "        self.predict = theano.function( \n",
    "            inputs=[x], \n",
    "            outputs = [ output_softmax_val] \n",
    "        )\n",
    "\n",
    "        \n",
    "    # x_mask and y_mask is the same\n",
    "    # x_test_mask and y_test_mask is the same\n",
    "    def fit(self, x_train, y_train, x_test,  y_test , x_mask, y_mask, x_test_mask, y_test_mask ):\n",
    "        print \" \"\n",
    "        print \"start training!!!!\"\n",
    "        print \" \"\n",
    "        \n",
    "        epochs = 0\n",
    "        for i in range(self.max_epochs):\n",
    "            epochs +=1\n",
    "            t0 = time()\n",
    "            \n",
    "            cs = 0.\n",
    "            pseudo_cs = 0.\n",
    "            for index in range(len(x_train)):\n",
    "                pseudo, cost, output_softmax = self.train( x_train[index] , y_train[index],\n",
    "                                                          x_mask[index], y_mask[index])\n",
    "                cs += cost\n",
    "                pseudo_cs += pseudo\n",
    "                gg = index\n",
    "#                 print pseudo, cost\n",
    "                \n",
    "            cs /= len(x_train)\n",
    "            pseudo_cs /= len(x_train)\n",
    "            \n",
    "#             cPickle.dump( self , open(\"./\"+self.file_name+\".pkl\",\"wb\"))\n",
    "            if epochs <= 1:\n",
    "                previous_cs = \"-\"\n",
    "            else:\n",
    "                previous_cs = self.train_history_[-1]['cost']\n",
    "            print \"\\n===============================\"\n",
    "            print 'epoch {0} : pseudo= {1}, cost= {2}, previous_cost= {3}, train_time = {4} s'.format(epochs,\n",
    "                                                                                                      pseudo_cs, \n",
    "                                                                                                      cs,\n",
    "                                                                                                      previous_cs, \n",
    "                                                                                                      time() - t0)\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            t0 = time()\n",
    "            \n",
    "#             print np.argmax(output_softmax[:],axis=2)\n",
    "#             print decode_all( np.argmax(output_softmax[:],axis=2) , x_train_mask[gg],  batch_size , True)\n",
    "            \n",
    "            # save model first\n",
    "            # dont know the LER performance yet\n",
    "#             cPickle.dump( self , open(\"./\"+self.file_name+\".pkl\",\"wb\"))\n",
    "    \n",
    "\n",
    "            err = 0.\n",
    "            for index in range( len(x_test) ) :\n",
    "\n",
    "                prepre = self.predict( x_test[index])\n",
    "                \n",
    "                err += check_phone_err(y_test[index], np.argmax(prepre[0],axis=2), \n",
    "                                           y_test_mask[index], x_test_mask[index], batch_size)\n",
    "#                 label_error_rate += check_all( y_test[index], y_test_mask[index],\n",
    "#                                               np.argmax(prepre[0],axis=2) , x_test_mask[index],\n",
    "#                                               batch_size)\n",
    "                \n",
    "#                 if (( index + epochs ) % 4 == 0 ):\n",
    "#                     ## print actual\n",
    "#                     y_actual = decode_all_actual( y_test[index], y_test_mask[index], batch_size , True)\n",
    "\n",
    "#                     ## print pred\n",
    "#                     y_predict = decode_all_pred( np.argmax(prepre[0],axis=2) , x_test_mask[index],  batch_size , False)\n",
    "                \n",
    "            err /= len(x_test)\n",
    "            self.train_history_.append({\"epoch\":epochs, \"cost\": cs, \"err\":err})\n",
    "            \n",
    "            print '\\t\\t\\t val_= {0}, test_time  = {1} s'.format(err, time() - t0)\n",
    "            print \"===============================\\n\"\n",
    "            \n",
    "            sys.stdout.flush()\n",
    "            \n",
    "#             for a , b in zip (y_actual,y_predict):\n",
    "#                 print a \n",
    "#                 print \"====>>\",b\n",
    "            \n",
    "#             sys.stdout.flush()\n",
    "            \n",
    "            \"\"\"\n",
    "            should use cost do early stopping\n",
    "            \"\"\"\n",
    "            current_cs = self.train_history_[-1]['cost']\n",
    "            current_epoch = self.train_history_[-1]['epoch']\n",
    "            if current_cs < self.best_valid:\n",
    "                self.best_valid = current_cs\n",
    "                self.best_valid_epoch = current_epoch\n",
    "                self.best_params = [w.get_value() for w in self.all_params]\n",
    "                cPickle.dump( self , open(\"./\"+self.file_name+\".pkl\",\"wb\"))\n",
    "                \n",
    "            elif self.best_valid_epoch + self.patience <= current_epoch:\n",
    "                print \"\"\n",
    "                print \"Early stopping.\"\n",
    "                print self.best_valid_epoch,self.best_valid\n",
    "                print \"Best valid ler {:.6f} at epoch {}.\".format(self.best_valid, self.best_valid_epoch)              \n",
    "#                 for qq in range (len(self.all_params)):\n",
    "#                     self.all_params[qq].set_value( self.best_params[qq] )\n",
    "#                 break\n",
    "\n",
    "            \"\"\"\n",
    "            can not use label error rate do early stopping\n",
    "            \"\"\"\n",
    "#             current_ler = self.train_history_[-1]['LER']\n",
    "#             current_epoch = self.train_history_[-1]['epoch']\n",
    "#             if current_ler < self.best_valid:\n",
    "# #                 print \"********************* Now best ************************\"\n",
    "#                 sys.stdout.flush()\n",
    "#                 self.best_valid = current_ler\n",
    "#                 self.best_valid_epoch = current_epoch\n",
    "#                 self.best_params = [w.get_value() for w in self.all_params]\n",
    "# #                 cPickle.dump( self , open(\"./\"+self.file_name+\".pkl\",\"wb\"))\n",
    "                \n",
    "#             elif self.best_valid_epoch + self.patience <= current_epoch:\n",
    "#                 print \"\"\n",
    "#                 print \"Early stopping.\"\n",
    "#                 print self.best_valid_epoch,self.best_valid\n",
    "#                 print \"Best valid ler {:.6f} at epoch {}.\".format(self.best_valid, self.best_valid_epoch)\n",
    "#                 sys.stdout.flush()                \n",
    "#                 for qq in range (len(self.all_params)):\n",
    "#                     self.all_params[qq].set_value( self.best_params[qq] )\n",
    "#                 break\n",
    "\n",
    "\n",
    "#     def prediction(self, x, x_mask) :\n",
    "        \n",
    "#         abc =  self.predict(x, x_mask)\n",
    "        \n",
    "#         return np.argmax(abc[0], axis = 1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'char_unmap' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-42cd0ed24034>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnum_classes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_unmap\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mblank_symbol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchar_unmap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[0mblank_symbol\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'char_unmap' is not defined"
     ]
    }
   ],
   "source": [
    "num_classes = len(char_unmap) - 2\n",
    "blank_symbol = len(char_unmap)- 1\n",
    "print num_classes\n",
    "print blank_symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pika/nntools/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
      "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n",
      "/home/pika/anaconda/lib/python2.7/site-packages/theano/scan_module/scan.py:1017: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
      "  'must be passed as a part of non_sequences', Warning)\n",
      "/home/pika/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-afc0db860db0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mup_momentum\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mpatience\u001b[0m         \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"model_phone_1\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m )\n",
      "\u001b[1;32m<ipython-input-5-93d159851a4c>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, max_seq_length, hidden_layer, rnn_hidden_layer, batch, max_epochs, eval_size, output_num_units, patience, up_learning_rate, up_momentum, file_name)\u001b[0m\n\u001b[0;32m    219\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mpseudo_cost\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_softmax_train\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[1;31m#             outputs = [output_lin_ctc, output_softmax, cost],\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m             \u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m         )\n\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/compile/function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 profile=profile)\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/compile/pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    509\u001b[0m     return orig_function(inputs, cloned_outputs, mode,\n\u001b[0;32m    510\u001b[0m             \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             on_unused_input=on_unused_input)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input)\u001b[0m\n\u001b[0;32m   1465\u001b[0m                    \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1466\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1467\u001b[1;33m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1468\u001b[0m                        defaults)\n\u001b[0;32m   1469\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph)\u001b[0m\n\u001b[0;32m   1160\u001b[0m                         optimizer, inputs, outputs)\n\u001b[0;32m   1161\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m                     \u001b[0moptimizer_profile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m                 \u001b[0mend_optimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mSame\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \"\"\"\n\u001b[1;32m---> 90\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_requirements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m                 \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m                 \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph, start_from)\u001b[0m\n\u001b[0;32m   1790\u001b[0m                 \u001b[0mnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnb_imported\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1791\u001b[0m                 \u001b[0mt_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1792\u001b[1;33m                 \u001b[0mgopt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1793\u001b[0m                 \u001b[0mtime_opts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgopt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt_opt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1794\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mchange_tracker\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchanged\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m                 \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m                 \u001b[0msub_prof\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m                 \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m                 \u001b[0msub_profs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msub_prof\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/gof/opt.pyc\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, fgraph, *args, **kwargs)\u001b[0m\n\u001b[0;32m     79\u001b[0m             \u001b[0morig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0morig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_opt.pyc\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, fgraph)\u001b[0m\n\u001b[0;32m    214\u001b[0m                                                                scan_op.Scan)]\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocess_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprocess_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_opt.pyc\u001b[0m in \u001b[0;36mprocess_node\u001b[1;34m(self, fgraph, node)\u001b[0m\n\u001b[0;32m    308\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnd\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexistent_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m             \u001b[0mto_keep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_replace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m             if (out in to_keep\n\u001b[0;32m    312\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexistent_nodes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model2 = end_to_end (\n",
    "    input_shape      = (1, x_train.shape[3] ) , # batch of 1, (110, 30, 777, 117) 103, 32, 980, 128\n",
    "#     input_shape = (1, 117),\n",
    "    max_seq_length = x_train.shape[2],\n",
    "    hidden_layer     = [ 250, 250 , 250, 250, 200 ], # maximum layer to LSTM 3 layer only\n",
    "    rnn_hidden_layer = [ 100 ], # maximum layer to 1 layer only\n",
    "    batch            = batch_size, \n",
    "    max_epochs       = 300, \n",
    "    eval_size        = 0.1, \n",
    "    output_num_units = [ len(phones_mapping) + 1 ],\n",
    "    up_learning_rate = 0.1, \n",
    "    up_momentum      = 0.9, \n",
    "    patience         = 5,\n",
    "    file_name = \"model_phone_1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for qq in range (len(model1.all_params)):\n",
    "    model2.all_params[qq].set_value( model1.all_params[qq].get_value() )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x_mask and y_mask is the same\n",
    "# x_test_mask and y_test_mask is the same\n",
    "\n",
    "%time model2.fit( x_train, y_train, x_valid, y_valid, x_train_mask, y_train_mask , x_valid_mask, y_valid_mask )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3 testing\n",
    "\n",
    "## with validation data set, with proper predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set model 2 result to model 3 first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pika/nntools/lasagne/layers/helper.py:69: UserWarning: get_all_layers() has been changed to return layers in topological order. The former implementation is still available as get_all_layers_old(), but will be removed before the first release of Lasagne. To ignore this warning, use `warnings.filterwarnings('ignore', '.*topo.*')`.\n",
      "  warnings.warn(\"get_all_layers() has been changed to return layers in \"\n",
      "/home/pika/anaconda/lib/python2.7/site-packages/theano/scan_module/scan.py:1017: Warning: In the strict mode, all neccessary shared variables must be passed as a part of non_sequences\n",
      "  'must be passed as a part of non_sequences', Warning)\n",
      "/home/pika/anaconda/lib/python2.7/site-packages/theano/scan_module/scan_perform_ext.py:133: RuntimeWarning: numpy.ndarray size changed, may indicate binary incompatibility\n",
      "  from scan_perform.scan_perform import *\n"
     ]
    }
   ],
   "source": [
    "model1 = end_to_end (\n",
    "    input_shape      = (1, x_train.shape[3] ) , # batch of 1, (110, 30, 777, 117) 103, 32, 980, 128\n",
    "#     input_shape = (1, 117),\n",
    "    max_seq_length = x_train.shape[2],\n",
    "    hidden_layer     = [ 250, 250 , 250, 250, 200 ], # maximum layer to LSTM 3 layer only\n",
    "    rnn_hidden_layer = [ 100 ], # maximum layer to 1 layer only\n",
    "    batch            = batch_size, \n",
    "    max_epochs       = 300, \n",
    "    eval_size        = 0.1, \n",
    "    output_num_units = [ len(phones_mapping) + 1 ],\n",
    "    up_learning_rate = 0.1, \n",
    "    up_momentum      = 0.9, \n",
    "    patience         = 5,\n",
    "    file_name = \"model_phone_1\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Error allocating 11636352 bytes of device memory (out of memory).\nApply node that caused the error: GpuFromHost(X)\nInputs types: [TensorType(float32, 3D)]\nInputs shapes: [(32, 777, 117)]\nInputs strides: [(363636, 468, 4)]\nInputs values: ['not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-0c7e2e7d2f18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mabc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    606\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_of_error\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                         storage_map=self.fn.storage_map)\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m                     \u001b[1;31m# For the c linker We don't have access from\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Error allocating 11636352 bytes of device memory (out of memory).\nApply node that caused the error: GpuFromHost(X)\nInputs types: [TensorType(float32, 3D)]\nInputs shapes: [(32, 777, 117)]\nInputs strides: [(363636, 468, 4)]\nInputs values: ['not shown']\n\nHINT: Re-running with most Theano optimization disabled could give you a back-trace of when this node was created. This can be done with by setting the Theano flag 'optimizer=fast_compile'. If that does not work, Theano optimizations can be disabled with 'optimizer=None'.\nHINT: Use the Theano flag 'exception_verbosity=high' for a debugprint and storage map footprint of this apply node."
     ]
    }
   ],
   "source": [
    "abc = model1.predict( x_train[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check_phone_err(y_actual, y_pred, y_mask_actual, y_mask_pred, batch_size):\n",
    "print np.argmax(abc[0],axis=2).shape\n",
    "check_phone_err(y_train[0], np.argmax(abc[0],axis=2), y_train_mask[0], x_train_mask[0],  batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%time model1.fit( x_train, y_train, x_valid, y_valid, x_train_mask, y_train_mask , x_valid_mask, y_valid_mask )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cPickle.dump( net5_see_see , open(\"./model_phone_1_poor.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cost': inf, 'epoch': 1, 'err': 31.991835016835022},\n",
       " {'cost': inf, 'epoch': 2, 'err': 31.833766586503668},\n",
       " {'cost': inf, 'epoch': 3, 'err': 31.990362297277194},\n",
       " {'cost': 158.0561217521001, 'epoch': 4, 'err': 31.910177979695053},\n",
       " {'cost': 145.73339465983864, 'epoch': 1, 'err': 31.15705348607041},\n",
       " {'cost': 149.67699106457164, 'epoch': 2, 'err': 31.068273132204926},\n",
       " {'cost': 137.5012452949598, 'epoch': 3, 'err': 31.068467382399174},\n",
       " {'cost': 133.60652227309143, 'epoch': 4, 'err': 31.07160217863742},\n",
       " {'cost': 129.87853915020099, 'epoch': 5, 'err': 31.065869979801775},\n",
       " {'cost': 125.51542426544486, 'epoch': 6, 'err': 31.068467382399174},\n",
       " {'cost': 118.49587975659416, 'epoch': 7, 'err': 31.059983174655027},\n",
       " {'cost': 109.07098907174417, 'epoch': 8, 'err': 30.968467507847684},\n",
       " {'cost': 101.07294819655928, 'epoch': 9, 'err': 30.368506854381739},\n",
       " {'cost': 94.865259781624502, 'epoch': 10, 'err': 29.317447069115506},\n",
       " {'cost': 86.062599182128906, 'epoch': 11, 'err': 27.279360794857947},\n",
       " {'cost': 82.311734393962382, 'epoch': 12, 'err': 26.380852430169117},\n",
       " {'cost': 74.919584922420171, 'epoch': 13, 'err': 24.644408630310853},\n",
       " {'cost': 68.508534292572904, 'epoch': 14, 'err': 22.828580942959515},\n",
       " {'cost': 62.69338100396314, 'epoch': 15, 'err': 20.484032066172226},\n",
       " {'cost': 57.900129151575776, 'epoch': 16, 'err': 19.02622742478097},\n",
       " {'cost': 53.8564496827357, 'epoch': 17, 'err': 17.458662060544842},\n",
       " {'cost': 50.56075727592394, 'epoch': 18, 'err': 16.176142033505883},\n",
       " {'cost': 47.619909897591306, 'epoch': 19, 'err': 15.005869544307801},\n",
       " {'cost': 45.294724695890849, 'epoch': 20, 'err': 14.520357414939383},\n",
       " {'cost': 42.929638834832943, 'epoch': 21, 'err': 13.777528908585525},\n",
       " {'cost': 40.9403796520048, 'epoch': 22, 'err': 13.2359995343754},\n",
       " {'cost': 49.055306147603154, 'epoch': 23, 'err': 12.935495780464594},\n",
       " {'cost': 40.638058838335056, 'epoch': 24, 'err': 13.749930548504626},\n",
       " {'cost': 38.888562137640797, 'epoch': 25, 'err': 13.007503727190596},\n",
       " {'cost': 38.25218296976923, 'epoch': 26, 'err': 12.288467236363708},\n",
       " {'cost': inf, 'epoch': 27, 'err': 12.039396528972764},\n",
       " {'cost': inf, 'epoch': 28, 'err': 12.049497127006351},\n",
       " {'cost': 36.207792541355765, 'epoch': 29, 'err': 11.763847147726322},\n",
       " {'cost': inf, 'epoch': 30, 'err': 11.601513360228701},\n",
       " {'cost': inf, 'epoch': 31, 'err': 11.899219025299686},\n",
       " {'cost': inf, 'epoch': 32, 'err': 11.581815529516982},\n",
       " {'cost': inf, 'epoch': 33, 'err': 12.068132678495958},\n",
       " {'cost': inf, 'epoch': 34, 'err': 11.543922288190513},\n",
       " {'cost': 36.619605906958718, 'epoch': 35, 'err': 11.611219828142488},\n",
       " {'cost': inf, 'epoch': 36, 'err': 11.387848681714903},\n",
       " {'cost': inf, 'epoch': 37, 'err': 11.20302343222242},\n",
       " {'cost': inf, 'epoch': 38, 'err': 11.255158743162001},\n",
       " {'cost': 33.375544223970579, 'epoch': 39, 'err': 11.125875113475701},\n",
       " {'cost': 35.218465582838334, 'epoch': 40, 'err': 11.158497663757684},\n",
       " {'cost': inf, 'epoch': 41, 'err': 11.20681739886391},\n",
       " {'cost': 31.535751990901613, 'epoch': 42, 'err': 11.058180676315251},\n",
       " {'cost': 32.373908811402551, 'epoch': 43, 'err': 10.941274980967295},\n",
       " {'cost': 31.102770444258901, 'epoch': 44, 'err': 10.824519051221012},\n",
       " {'cost': inf, 'epoch': 45, 'err': 10.700670332126917},\n",
       " {'cost': inf, 'epoch': 46, 'err': 10.703914053142933},\n",
       " {'cost': inf, 'epoch': 47, 'err': 10.556609399154906},\n",
       " {'cost': 27.900754280460692, 'epoch': 48, 'err': 10.578442241871965},\n",
       " {'cost': 26.889455869359878, 'epoch': 49, 'err': 10.579047972614042},\n",
       " {'cost': 26.557862865114675, 'epoch': 50, 'err': 10.620187105709414},\n",
       " {'cost': 25.454437570664489, 'epoch': 51, 'err': 10.382240056582281},\n",
       " {'cost': 25.165253000351989, 'epoch': 52, 'err': 10.39608825997942},\n",
       " {'cost': 23.434111400715356, 'epoch': 53, 'err': 10.375668452160157},\n",
       " {'cost': 22.707675415335348, 'epoch': 54, 'err': 10.216506369907806},\n",
       " {'cost': 21.851259287121227, 'epoch': 55, 'err': 10.307053824933373}]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net5_see_see.train_history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'cost': inf, 'epoch': 1, 'err': 31.991835016835022},\n",
       " {'cost': inf, 'epoch': 2, 'err': 31.833766586503668},\n",
       " {'cost': inf, 'epoch': 3, 'err': 31.990362297277194},\n",
       " {'cost': 158.0561217521001, 'epoch': 4, 'err': 31.910177979695053},\n",
       " {'cost': 145.73339465983864, 'epoch': 1, 'err': 31.15705348607041},\n",
       " {'cost': 149.67699106457164, 'epoch': 2, 'err': 31.068273132204926},\n",
       " {'cost': 137.5012452949598, 'epoch': 3, 'err': 31.068467382399174},\n",
       " {'cost': 133.60652227309143, 'epoch': 4, 'err': 31.07160217863742},\n",
       " {'cost': 129.87853915020099, 'epoch': 5, 'err': 31.065869979801775},\n",
       " {'cost': 125.51542426544486, 'epoch': 6, 'err': 31.068467382399174},\n",
       " {'cost': 118.49587975659416, 'epoch': 7, 'err': 31.059983174655027},\n",
       " {'cost': 109.07098907174417, 'epoch': 8, 'err': 30.968467507847684},\n",
       " {'cost': 101.07294819655928, 'epoch': 9, 'err': 30.368506854381739},\n",
       " {'cost': 94.865259781624502, 'epoch': 10, 'err': 29.317447069115506},\n",
       " {'cost': 86.062599182128906, 'epoch': 11, 'err': 27.279360794857947},\n",
       " {'cost': 82.311734393962382, 'epoch': 12, 'err': 26.380852430169117},\n",
       " {'cost': 74.919584922420171, 'epoch': 13, 'err': 24.644408630310853},\n",
       " {'cost': 68.508534292572904, 'epoch': 14, 'err': 22.828580942959515},\n",
       " {'cost': 62.69338100396314, 'epoch': 15, 'err': 20.484032066172226},\n",
       " {'cost': 57.900129151575776, 'epoch': 16, 'err': 19.02622742478097},\n",
       " {'cost': 53.8564496827357, 'epoch': 17, 'err': 17.458662060544842},\n",
       " {'cost': 50.56075727592394, 'epoch': 18, 'err': 16.176142033505883},\n",
       " {'cost': 47.619909897591306, 'epoch': 19, 'err': 15.005869544307801},\n",
       " {'cost': 45.294724695890849, 'epoch': 20, 'err': 14.520357414939383},\n",
       " {'cost': 42.929638834832943, 'epoch': 21, 'err': 13.777528908585525},\n",
       " {'cost': 40.9403796520048, 'epoch': 22, 'err': 13.2359995343754},\n",
       " {'cost': 49.055306147603154, 'epoch': 23, 'err': 12.935495780464594},\n",
       " {'cost': 40.638058838335056, 'epoch': 24, 'err': 13.749930548504626},\n",
       " {'cost': 38.888562137640797, 'epoch': 25, 'err': 13.007503727190596},\n",
       " {'cost': 38.25218296976923, 'epoch': 26, 'err': 12.288467236363708},\n",
       " {'cost': inf, 'epoch': 27, 'err': 12.039396528972764},\n",
       " {'cost': inf, 'epoch': 28, 'err': 12.049497127006351},\n",
       " {'cost': 36.207792541355765, 'epoch': 29, 'err': 11.763847147726322},\n",
       " {'cost': inf, 'epoch': 30, 'err': 11.601513360228701},\n",
       " {'cost': inf, 'epoch': 31, 'err': 11.899219025299686},\n",
       " {'cost': inf, 'epoch': 32, 'err': 11.581815529516982},\n",
       " {'cost': inf, 'epoch': 33, 'err': 12.068132678495958},\n",
       " {'cost': inf, 'epoch': 34, 'err': 11.543922288190513},\n",
       " {'cost': 36.619605906958718, 'epoch': 35, 'err': 11.611219828142488},\n",
       " {'cost': inf, 'epoch': 36, 'err': 11.387848681714903},\n",
       " {'cost': inf, 'epoch': 37, 'err': 11.20302343222242},\n",
       " {'cost': inf, 'epoch': 38, 'err': 11.255158743162001},\n",
       " {'cost': 33.375544223970579, 'epoch': 39, 'err': 11.125875113475701},\n",
       " {'cost': 35.218465582838334, 'epoch': 40, 'err': 11.158497663757684},\n",
       " {'cost': inf, 'epoch': 41, 'err': 11.20681739886391},\n",
       " {'cost': 31.535751990901613, 'epoch': 42, 'err': 11.058180676315251},\n",
       " {'cost': 32.373908811402551, 'epoch': 43, 'err': 10.941274980967295},\n",
       " {'cost': 31.102770444258901, 'epoch': 44, 'err': 10.824519051221012},\n",
       " {'cost': inf, 'epoch': 45, 'err': 10.700670332126917},\n",
       " {'cost': inf, 'epoch': 46, 'err': 10.703914053142933},\n",
       " {'cost': inf, 'epoch': 47, 'err': 10.556609399154906},\n",
       " {'cost': 27.900754280460692, 'epoch': 48, 'err': 10.578442241871965},\n",
       " {'cost': 26.889455869359878, 'epoch': 49, 'err': 10.579047972614042},\n",
       " {'cost': 26.557862865114675, 'epoch': 50, 'err': 10.620187105709414},\n",
       " {'cost': 25.454437570664489, 'epoch': 51, 'err': 10.382240056582281},\n",
       " {'cost': 25.165253000351989, 'epoch': 52, 'err': 10.39608825997942},\n",
       " {'cost': 23.434111400715356, 'epoch': 53, 'err': 10.375668452160157},\n",
       " {'cost': 22.707675415335348, 'epoch': 54, 'err': 10.216506369907806},\n",
       " {'cost': 21.851259287121227, 'epoch': 55, 'err': 10.307053824933373},\n",
       " {'cost': 20.969113590647872, 'epoch': 1, 'err': 10.196450027067383},\n",
       " {'cost': 20.13804119998969, 'epoch': 2, 'err': 10.169546263455342},\n",
       " {'cost': 19.369946174251222, 'epoch': 3, 'err': 10.20316197182885},\n",
       " {'cost': 18.493689527789368, 'epoch': 4, 'err': 10.068920830518749},\n",
       " {'cost': 17.566035863265249, 'epoch': 5, 'err': 10.183433043927948},\n",
       " {'cost': 17.125433986626781, 'epoch': 6, 'err': 10.033324149047518},\n",
       " {'cost': 16.255410944373864, 'epoch': 7, 'err': 10.326031968080601},\n",
       " {'cost': 15.559223443559073, 'epoch': 8, 'err': 10.105825537005098},\n",
       " {'cost': 14.840477119371728, 'epoch': 9, 'err': 10.071974811507202},\n",
       " {'cost': 14.158111433381016, 'epoch': 10, 'err': 10.118882163334897},\n",
       " {'cost': 13.468488943229602, 'epoch': 11, 'err': 9.9605252368993931},\n",
       " {'cost': 19.660958160474461, 'epoch': 12, 'err': 10.314803598308764},\n",
       " {'cost': inf, 'epoch': 13, 'err': 10.725483634104846},\n",
       " {'cost': inf, 'epoch': 14, 'err': 21.097605377794153},\n",
       " {'cost': inf, 'epoch': 15, 'err': 12.381517258570023},\n",
       " {'cost': inf, 'epoch': 16, 'err': 25.741573572495835},\n",
       " {'cost': inf, 'epoch': 17, 'err': 26.384107866372496},\n",
       " {'cost': inf, 'epoch': 18, 'err': 25.956557616038786},\n",
       " {'cost': inf, 'epoch': 19, 'err': 29.556299081888707},\n",
       " {'cost': inf, 'epoch': 20, 'err': 28.452320473822034},\n",
       " {'cost': inf, 'epoch': 21, 'err': 30.241173133468575},\n",
       " {'cost': inf, 'epoch': 22, 'err': 30.297906123348209},\n",
       " {'cost': inf, 'epoch': 23, 'err': 30.47380368107466},\n",
       " {'cost': inf, 'epoch': 24, 'err': 30.53013188539926},\n",
       " {'cost': inf, 'epoch': 25, 'err': 30.402326942612884},\n",
       " {'cost': inf, 'epoch': 26, 'err': 30.503906646889483},\n",
       " {'cost': inf, 'epoch': 27, 'err': 30.416880401315243},\n",
       " {'cost': inf, 'epoch': 28, 'err': 30.618484396797033},\n",
       " {'cost': inf, 'epoch': 29, 'err': 30.301163419453744},\n",
       " {'cost': inf, 'epoch': 30, 'err': 30.016970059042343},\n",
       " {'cost': inf, 'epoch': 31, 'err': 30.104735191910745},\n",
       " {'cost': inf, 'epoch': 32, 'err': 30.122616246778673},\n",
       " {'cost': inf, 'epoch': 33, 'err': 30.110138541784934},\n",
       " {'cost': inf, 'epoch': 34, 'err': 30.051767082041181}]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net5_see_see.train_history_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "start training!!!!\n",
      " \n",
      "\n",
      "===============================\n",
      "epoch 1 : pseudo= -7.40411556346, cost= 20.9691135906, previous_cost= -, train_time = 1261.18023181 s\n",
      "\t\t\t val_= 10.1964500271, test_time  = 11.3013911247 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 2 : pseudo= -7.56373995253, cost= 20.1380412, previous_cost= 20.9691135906, train_time = 1257.9420011 s\n",
      "\t\t\t val_= 10.1695462635, test_time  = 11.279168129 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 3 : pseudo= -7.59256823086, cost= 19.3699461743, previous_cost= 20.1380412, train_time = 1259.6684761 s\n",
      "\t\t\t val_= 10.2031619718, test_time  = 11.2603580952 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 4 : pseudo= -7.71768305834, cost= 18.4936895278, previous_cost= 19.3699461743, train_time = 1259.86650395 s\n",
      "\t\t\t val_= 10.0689208305, test_time  = 11.2160029411 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 5 : pseudo= -7.84211264999, cost= 17.5660358633, previous_cost= 18.4936895278, train_time = 1260.40985894 s\n",
      "\t\t\t val_= 10.1834330439, test_time  = 11.2208349705 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 6 : pseudo= -7.72274692776, cost= 17.1254339866, previous_cost= 17.5660358633, train_time = 1259.11413097 s\n",
      "\t\t\t val_= 10.033324149, test_time  = 11.21185112 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 7 : pseudo= -7.84594578419, cost= 16.2554109444, previous_cost= 17.1254339866, train_time = 1263.00003409 s\n",
      "\t\t\t val_= 10.3260319681, test_time  = 11.2644081116 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 8 : pseudo= -7.88140009445, cost= 15.5592234436, previous_cost= 16.2554109444, train_time = 1259.20824504 s\n",
      "\t\t\t val_= 10.105825537, test_time  = 11.2751607895 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 9 : pseudo= -7.95839008313, cost= 14.8404771194, previous_cost= 15.5592234436, train_time = 1260.26617479 s\n",
      "\t\t\t val_= 10.0719748115, test_time  = 11.3034071922 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 10 : pseudo= -7.91686722839, cost= 14.1581114334, previous_cost= 14.8404771194, train_time = 1259.62506604 s\n",
      "\t\t\t val_= 10.1188821633, test_time  = 11.2686481476 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 11 : pseudo= -7.96193249249, cost= 13.4684889432, previous_cost= 14.1581114334, train_time = 1262.16318989 s\n",
      "\t\t\t val_= 9.9605252369, test_time  = 11.2429859638 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 12 : pseudo= -2.16298755049, cost= 19.6609581605, previous_cost= 13.4684889432, train_time = 1258.74068093 s\n",
      "\t\t\t val_= 10.3148035983, test_time  = 11.3048369884 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 13 : pseudo= 8.51855201166, cost= inf, previous_cost= 19.6609581605, train_time = 1259.98235202 s\n",
      "\t\t\t val_= 10.7254836341, test_time  = 11.2028019428 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 14 : pseudo= 352.148233856, cost= inf, previous_cost= inf, train_time = 1258.90027118 s\n",
      "\t\t\t val_= 21.0976053778, test_time  = 10.2850699425 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 15 : pseudo= 1028.58799081, cost= inf, previous_cost= inf, train_time = 1258.37744713 s\n",
      "\t\t\t val_= 12.3815172586, test_time  = 11.0641491413 s\n",
      "===============================\n",
      "\n",
      "\n",
      "===============================\n",
      "epoch 16 : pseudo= 761.740963346, cost= inf, previous_cost= inf, train_time = 1258.69794393 s\n",
      "\t\t\t val_= 25.7415735725, test_time  = 9.85512089729 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 17 : pseudo= 1839.41569326, cost= inf, previous_cost= inf, train_time = 1260.72775006 s\n",
      "\t\t\t val_= 26.3841078664, test_time  = 9.845443964 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 18 : pseudo= 1494.40335172, cost= inf, previous_cost= inf, train_time = 1258.51214314 s\n",
      "\t\t\t val_= 25.956557616, test_time  = 9.83231902122 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 19 : pseudo= 1722.01857721, cost= inf, previous_cost= inf, train_time = 1258.87020302 s\n",
      "\t\t\t val_= 29.5562990819, test_time  = 9.59384298325 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 20 : pseudo= 1543.62684409, cost= inf, previous_cost= inf, train_time = 1260.23391104 s\n",
      "\t\t\t val_= 28.4523204738, test_time  = 9.62340807915 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 21 : pseudo= 1928.37732882, cost= inf, previous_cost= inf, train_time = 1258.67718816 s\n",
      "\t\t\t val_= 30.2411731335, test_time  = 9.47936105728 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 22 : pseudo= 1584.98492372, cost= inf, previous_cost= inf, train_time = 1259.4937079 s\n",
      "\t\t\t val_= 30.2979061233, test_time  = 9.48068714142 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 23 : pseudo= 1621.27416518, cost= inf, previous_cost= inf, train_time = 1261.060606 s\n",
      "\t\t\t val_= 30.4738036811, test_time  = 9.45449590683 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 24 : pseudo= 2058.52015582, cost= inf, previous_cost= inf, train_time = 1261.93220782 s\n",
      "\t\t\t val_= 30.5301318854, test_time  = 9.4160630703 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 25 : pseudo= 1895.91618392, cost= inf, previous_cost= inf, train_time = 1262.5921371 s\n",
      "\t\t\t val_= 30.4023269426, test_time  = 9.43670797348 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 26 : pseudo= 1753.74724097, cost= inf, previous_cost= inf, train_time = 1262.49559498 s\n",
      "\t\t\t val_= 30.5039066469, test_time  = 9.44096207619 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 27 : pseudo= 1821.70241391, cost= inf, previous_cost= inf, train_time = 1262.15490913 s\n",
      "\t\t\t val_= 30.4168804013, test_time  = 9.37629079819 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 28 : pseudo= 1712.45685585, cost= inf, previous_cost= inf, train_time = 1262.18029714 s\n",
      "\t\t\t val_= 30.6184843968, test_time  = 9.40462994576 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 29 : pseudo= 1561.53519062, cost= inf, previous_cost= inf, train_time = 1261.98342085 s\n",
      "\t\t\t val_= 30.3011634195, test_time  = 9.41993188858 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 30 : pseudo= 1477.89529923, cost= inf, previous_cost= inf, train_time = 1261.79826617 s\n",
      "\t\t\t val_= 30.016970059, test_time  = 9.4961950779 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 31 : pseudo= 1129.5490059, cost= inf, previous_cost= inf, train_time = 1262.10612988 s\n",
      "\t\t\t val_= 30.1047351919, test_time  = 9.45661902428 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 32 : pseudo= 1246.88377069, cost= inf, previous_cost= inf, train_time = 1259.87446785 s\n",
      "\t\t\t val_= 30.1226162468, test_time  = 9.46172499657 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 33 : pseudo= 1176.45977961, cost= inf, previous_cost= inf, train_time = 1258.67447686 s\n",
      "\t\t\t val_= 30.1101385418, test_time  = 9.43577384949 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n",
      "\n",
      "===============================\n",
      "epoch 34 : pseudo= 1213.94042139, cost= inf, previous_cost= inf, train_time = 1259.63444996 s\n",
      "\t\t\t val_= 30.051767082, test_time  = 9.47287678719 s\n",
      "===============================\n",
      "\n",
      "\n",
      "Early stopping.\n",
      "11 13.4684889432\n",
      "Best valid ler 13.468489 at epoch 11.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-de0b85a82077>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# x_test_mask and y_test_mask is the same\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time net5_see_see.fit( x_train, y_train, x_valid, y_valid, x_train_mask, y_train_mask , x_valid_mask, y_valid_mask )'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[1;34m(self, arg_s)\u001b[0m\n\u001b[0;32m   2302\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2303\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2304\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2305\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2306\u001b[0m     \u001b[1;31m#-------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2223\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2224\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2225\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2226\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2227\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    191\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 193\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1160\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'eval'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1161\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1162\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1163\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1164\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-93d159851a4c>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x_train, y_train, x_test, y_test, x_mask, y_mask, x_test_mask, y_test_mask)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                 pseudo, cost, output_softmax = self.train( x_train[index] , y_train[index],\n\u001b[1;32m--> 246\u001b[1;33m                                                           x_mask[index], y_mask[index])\n\u001b[0m\u001b[0;32m    247\u001b[0m                 \u001b[0mcs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m                 \u001b[0mpseudo_cs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpseudo\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    595\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 597\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    598\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    599\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/pika/anaconda/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mctx\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoContext\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    766\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 767\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    768\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    769\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# x_mask and y_mask is the same\n",
    "# x_test_mask and y_test_mask is the same\n",
    "\n",
    "%time net5_see_see.fit( x_train, y_train, x_valid, y_valid, x_train_mask, y_train_mask , x_valid_mask, y_valid_mask )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('model_phone_1.pkl', 'rb') as f:\n",
    "    net5_see_see = cPickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1153097"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del model1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
